import great_expectations as gx
import pandas as pd
import os
import json
from pathlib import Path
from great_expectations.validator.validator import Validator
from great_expectations.core.expectation_suite import ExpectationSuite



# ƒê∆∞·ªùng d·∫´n g·ªëc t·ªõi OMOP_Project
BASE_DIR = Path(__file__).resolve().parent.parent

# ƒê∆∞·ªùng d·∫´n d·ªØ li·ªáu v√† b√°o c√°o
PARQUET_DIR = BASE_DIR / "data" / "parquet"
REPORT_DIR = BASE_DIR / "data" / "validation_reports"
GE_TMP_DIR = BASE_DIR / "utils" / "gx_tmp"

REPORT_DIR.mkdir(parents=True, exist_ok=True)
GE_TMP_DIR.mkdir(parents=True, exist_ok=True)

# Custom rules per table
CUSTOM_EXPECTATIONS = {
    "person": {
        "expect_column_values_to_not_be_null": ["person_id"],
        "expect_column_values_to_be_between": {
            "year_of_birth": {"min_value": 1800, "max_value": 2025}
        }
    },
    "visit_occurrence": {
        "expect_column_values_to_be_of_type": {
            "visit_start_date": "datetime64[ns]"
        }
    }
}

# Auto-generate expectations from schema
def auto_generate_expectations(validator: Validator, df: pd.DataFrame):
    for col in df.columns:
        dtype = df[col].dtype
        if pd.api.types.is_numeric_dtype(dtype):
            validator.expect_column_values_to_be_of_type(col, "float64")
        elif pd.api.types.is_datetime64_any_dtype(dtype):
            validator.expect_column_values_to_be_of_type(col, "datetime64[ns]")
        elif pd.api.types.is_string_dtype(dtype):
            validator.expect_column_values_to_be_of_type(col, "object")
        validator.expect_column_values_to_not_be_null(col)

# Run validation on 1 table
def validate_table(table_name, file_path):
    print(f"üîç Validating {table_name}...")
    df = pd.read_parquet(file_path)

    # T·∫°o context (d√πng Fluent API)
    context = gx.get_context()

    # ‚úÖ T·∫°o expectation suite
    suite_name = f"{table_name}_suite"
    suite_identifier = ExpectationSuiteIdentifier(suite_name)

    # Ki·ªÉm tra n·∫øu suite ƒë√£ t·ªìn t·∫°i
    try:
        suite = context.expectations_store.get(suite_identifier)
    except KeyError:
        suite = ExpectationSuite(suite_name)
        context.expectations_store.set(key=suite_identifier)

    # T·∫°o validator tr·ª±c ti·∫øp t·ª´ DataFrame
    validator = context.get_validator(
        dataframe=df,
        expectation_suite_name=suite_name,
    )

    # G·ªçi auto generate expectation ho·∫∑c th√™m expectation custom
    auto_generate_expectations(validator, df)

    # # T·∫°o suite m·ªõi
    # suite = ExpectationSuite(name=suite_name)
    # context.suites.add(suite)
    #
    # # ‚úÖ T·∫°o validator tr·ª±c ti·∫øp t·ª´ DataFrame (kh√¥ng c·∫ßn batch hay datasource th√™m)
    # validator = context.data_sources.pandas_default.add_dataframe(
    #     name=table_name,
    #     dataframe=df,
    #     expectation_suite=suite,
    # )


    # ‚úÖ Auto-generate expectations
    auto_generate_expectations(validator, df)

    # ‚úÖ Add custom expectations n·∫øu c√≥
    expectations = CUSTOM_EXPECTATIONS.get(table_name, {})
    for col in expectations.get("expect_column_values_to_not_be_null", []):
        validator.expect_column_values_to_not_be_null(col)

    for col, limits in expectations.get("expect_column_values_to_be_between", {}).items():
        validator.expect_column_values_to_be_between(col, **limits)

    for col, dtype in expectations.get("expect_column_values_to_be_of_type", {}).items():
        validator.expect_column_values_to_be_of_type(col, dtype)

    # ‚úÖ Run validation
    result = validator.validate()

    # ‚úÖ Save JSON report
    report_path = REPORT_DIR / f"{table_name}_report.json"
    with open(report_path, "w") as f:
        json.dump(result.to_json_dict(), f, indent=2, default=str)

    # ‚úÖ Log result
    if result["success"]:
        print(f"‚úÖ {table_name} passed validation. Report saved at: {report_path}\n")
    else:
        print(f"‚ùå {table_name} failed validation. See report at: {report_path}\n")

    print(dir(context))
    print(context.__class__)

# Validate t·∫•t c·∫£ c√°c b·∫£ng
def validate_all():
    for file in os.listdir(PARQUET_DIR):
        if file.endswith(".parquet"):
            table_name = file.replace(".parquet", "")
            file_path = PARQUET_DIR / file
            validate_table(table_name, file_path)

if __name__ == "__main__":
    validate_all()


    #def validate():
    # Create data source
    #context = ge.get_context()

    # Follow this tutorial
    # https://legacy.017.docs.greatexpectations.io/docs/0.15.50/deployment_patterns/how_to_use_great_expectations_with_google_cloud_platform_and_bigquery/


